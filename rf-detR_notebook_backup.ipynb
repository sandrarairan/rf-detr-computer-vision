{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "✅ Modelo cargado correctamente\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "import supervision as sv\n",
    "from PIL import Image\n",
    "from rfdetr import RFDETRBase\n",
    "from rfdetr.util.coco_classes import COCO_CLASSES\n",
    "\n",
    "from rfdetr import RFDETRBase\n",
    "\n",
    "# Cargar el modelo con pesos preentrenados\n",
    "try:\n",
    "    model = RFDETRBase(pretrained=True)  # Esto carga automáticamente los pesos\n",
    "    print(\"✅ Modelo cargado correctamente\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error al cargar el modelo: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3550.)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "\n",
    "    detections = model.predict(frame, threshold=0.5)\n",
    "\n",
    "    labels = [\n",
    "        f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
    "        for class_id, confidence\n",
    "        in zip(detections.class_id, detections.confidence)\n",
    "    ]\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = sv.BoxAnnotator().annotate(annotated_frame, detections)\n",
    "    annotated_frame = sv.LabelAnnotator().annotate(annotated_frame, detections, labels)\n",
    "\n",
    "    cv2.imshow(\"Webcam\", annotated_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track every detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "\n",
      "===== RESUMEN DE DETECCIONES =====\n",
      "Total de frames procesados: 97\n",
      "Promedio de detecciones por frame: 1.85\n",
      "\n",
      "Top 5 objetos detectados:\n",
      "  - person: 97 detecciones (confianza promedio: 0.97)\n",
      "  - cell phone: 33 detecciones (confianza promedio: 0.63)\n",
      "  - remote: 13 detecciones (confianza promedio: 0.49)\n",
      "  - cup: 11 detecciones (confianza promedio: 0.91)\n",
      "  - book: 8 detecciones (confianza promedio: 0.44)\n",
      "\n",
      "Últimas 5 detecciones:\n",
      "  - 2025-04-02 18:07:32.417: person (0.95)\n",
      "  - 2025-04-02 18:07:32.417: book (0.45)\n",
      "  - 2025-04-02 18:07:33.484: person (0.95)\n",
      "  - 2025-04-02 18:07:34.553: person (0.95)\n",
      "  - 2025-04-02 18:07:34.553: book (0.45)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# Inicializar el modelo con resolución moderada para equilibrar velocidad y precisión\n",
    "model = RFDETRBase(resolution=448)\n",
    "\n",
    "# Inicializar webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "label_annotator = sv.LabelAnnotator()\n",
    "\n",
    "# Estructuras de datos para almacenar detecciones\n",
    "detection_history = {\n",
    "    'objects': defaultdict(int),           # Contador total por clase\n",
    "    'timestamps': [],                      # Timestamps de cada frame\n",
    "    'detections_per_frame': [],            # Número de detecciones por frame\n",
    "    'confidence_history': defaultdict(list) # Historial de confianza por clase\n",
    "}\n",
    "\n",
    "# Cola para mantener las últimas 100 detecciones (formato de registro)\n",
    "recent_detections = deque(maxlen=100)\n",
    "\n",
    "# Para calcular FPS\n",
    "prev_time = time.time()\n",
    "fps_history = deque(maxlen=30)  # Para calcular FPS promedio\n",
    "\n",
    "# Umbral de confianza para detecciones\n",
    "confidence_threshold = 0.4\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Leer frame de la webcam\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Registrar timestamp\n",
    "        current_time = datetime.now()\n",
    "        timestamp = current_time.strftime(\"%Y-%m-%d %H:%M:%S.%f\")[:-3]\n",
    "        detection_history['timestamps'].append(timestamp)\n",
    "\n",
    "        # Convertir frame de BGR a RGB para el modelo\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Ejecutar inferencia\n",
    "        detections = model.predict(rgb_frame, threshold=confidence_threshold)\n",
    "\n",
    "        # Registrar número de detecciones en este frame\n",
    "        num_detections = len(detections.confidence)\n",
    "        detection_history['detections_per_frame'].append(num_detections)\n",
    "\n",
    "        # Procesar y almacenar detecciones\n",
    "        frame_detections = []\n",
    "        for i, (class_id, confidence, box) in enumerate(zip(\n",
    "                detections.class_id,\n",
    "                detections.confidence,\n",
    "                detections.xyxy)):\n",
    "\n",
    "            class_name = COCO_CLASSES[class_id]\n",
    "\n",
    "            # Actualizar contador de objetos\n",
    "            detection_history['objects'][class_name] += 1\n",
    "\n",
    "            # Guardar historial de confianza\n",
    "            detection_history['confidence_history'][class_name].append(float(confidence))\n",
    "\n",
    "            # Crear registro detallado de esta detección\n",
    "            detection_record = {\n",
    "                'timestamp': timestamp,\n",
    "                'class_id': int(class_id),\n",
    "                'class_name': class_name,\n",
    "                'confidence': float(confidence),\n",
    "                'box': box.tolist(),\n",
    "                'frame_position': i\n",
    "            }\n",
    "\n",
    "            # Añadir a la cola de detecciones recientes\n",
    "            recent_detections.append(detection_record)\n",
    "            frame_detections.append(detection_record)\n",
    "\n",
    "        # Preparar etiquetas para visualización\n",
    "        labels = [\n",
    "            f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
    "            for class_id, confidence\n",
    "            in zip(detections.class_id, detections.confidence)\n",
    "        ]\n",
    "\n",
    "        # Anotar frame\n",
    "        annotated_frame = box_annotator.annotate(frame, detections)\n",
    "        annotated_frame = label_annotator.annotate(annotated_frame, detections, labels)\n",
    "\n",
    "        # Calcular y mostrar FPS\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        fps_history.append(fps)\n",
    "        avg_fps = sum(fps_history) / len(fps_history)\n",
    "        prev_time = current_time\n",
    "\n",
    "        # Mostrar estadísticas en el frame\n",
    "        cv2.putText(annotated_frame, f\"FPS: {avg_fps:.1f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        # Mostrar top 3 objetos detectados\n",
    "        top_objects = sorted(detection_history['objects'].items(),\n",
    "                             key=lambda x: x[1], reverse=True)[:3]\n",
    "        y_pos = 70\n",
    "        for obj_name, count in top_objects:\n",
    "            cv2.putText(annotated_frame, f\"{obj_name}: {count}\", (10, y_pos),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "            y_pos += 30\n",
    "\n",
    "        # Mostrar número de objetos en la escena actual\n",
    "        current_objects = {}\n",
    "        for det in frame_detections:\n",
    "            current_objects[det['class_name']] = current_objects.get(det['class_name'], 0) + 1\n",
    "\n",
    "        cv2.putText(annotated_frame, f\"Objetos actuales: {len(current_objects)}\",\n",
    "                    (10, y_pos + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Mostrar el resultado\n",
    "        cv2.imshow(\"RF-DETR Webcam Detection con Registro\", annotated_frame)\n",
    "\n",
    "        # Salir con la tecla 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detenido por el usuario\")\n",
    "finally:\n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Mostrar resumen de detecciones\n",
    "    print(\"\\n===== RESUMEN DE DETECCIONES =====\")\n",
    "    print(f\"Total de frames procesados: {len(detection_history['timestamps'])}\")\n",
    "    print(f\"Promedio de detecciones por frame: {np.mean(detection_history['detections_per_frame']):.2f}\")\n",
    "    print(\"\\nTop 5 objetos detectados:\")\n",
    "\n",
    "    for class_name, count in sorted(detection_history['objects'].items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "        avg_confidence = np.mean(detection_history['confidence_history'][class_name])\n",
    "        print(f\"  - {class_name}: {count} detecciones (confianza promedio: {avg_confidence:.2f})\")\n",
    "\n",
    "    print(f\"\\nÚltimas 5 detecciones:\")\n",
    "    for det in list(recent_detections)[-5:]:\n",
    "        print(f\"  - {det['timestamp']}: {det['class_name']} ({det['confidence']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect unique objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "Objeto actualizado/guardado: person (Confianza: 0.96)\n",
      "Objeto actualizado/guardado: person (Confianza: 0.96)\n",
      "Objeto actualizado/guardado: person (Confianza: 0.96)\n",
      "Objeto actualizado/guardado: person (Confianza: 0.96)\n",
      "Objeto actualizado/guardado: person (Confianza: 0.97)\n",
      "Objeto actualizado/guardado: apple (Confianza: 0.89)\n",
      "Objeto actualizado/guardado: apple (Confianza: 0.91)\n",
      "Objeto actualizado/guardado: apple (Confianza: 0.92)\n",
      "Objeto actualizado/guardado: cup (Confianza: 0.57)\n",
      "Objeto actualizado/guardado: cup (Confianza: 0.94)\n",
      "Objeto actualizado/guardado: cup (Confianza: 0.96)\n",
      "Objeto actualizado/guardado: remote (Confianza: 0.89)\n",
      "Objeto actualizado/guardado: cell phone (Confianza: 0.69)\n",
      "Objeto actualizado/guardado: cell phone (Confianza: 0.71)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Inicializar el modelo\n",
    "model = RFDETRBase()\n",
    "\n",
    "# Inicializar la captura de video\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Directorio para guardar los datos\n",
    "output_dir = \"objetos_detectados\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Archivo para el registro JSON\n",
    "json_file = os.path.join(output_dir, \"registro.json\")\n",
    "\n",
    "# Cargar registro existente si existe\n",
    "objects_registry = {}\n",
    "if os.path.exists(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        objects_registry = json.load(f)\n",
    "\n",
    "while True:\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        break\n",
    "    \n",
    "    # Realizar detección de objetos\n",
    "    detections = model.predict(frame, threshold=0.5)\n",
    "    \n",
    "    # Procesar cada detección\n",
    "    for i, (class_id, confidence, bbox) in enumerate(zip(detections.class_id, detections.confidence, detections.xyxy)):\n",
    "        # Obtener el nombre de la clase\n",
    "        class_name = COCO_CLASSES[class_id]\n",
    "        \n",
    "        # Verificar si es un objeto único (no detectado anteriormente)\n",
    "        # o si la detección actual tiene mayor confianza\n",
    "        if class_name not in objects_registry or confidence > objects_registry[class_name][\"confidence\"]:\n",
    "            # Extraer la región de interés (ROI)\n",
    "            x1, y1, x2, y2 = map(int, bbox)\n",
    "            roi = frame[y1:y2, x1:x2]\n",
    "            \n",
    "            # Guardar la imagen recortada\n",
    "            img_path = os.path.join(output_dir, f\"{class_name}.jpg\")\n",
    "            cv2.imwrite(img_path, roi)\n",
    "            \n",
    "            # Actualizar o crear registro\n",
    "            objects_registry[class_name] = {\n",
    "                \"confidence\": float(confidence),\n",
    "                \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                \"image_path\": img_path\n",
    "            }\n",
    "            \n",
    "            # Guardar registro actualizado\n",
    "            with open(json_file, 'w') as f:\n",
    "                json.dump(objects_registry, f, indent=4)\n",
    "            \n",
    "            print(f\"Objeto actualizado/guardado: {class_name} (Confianza: {confidence:.2f})\")\n",
    "    \n",
    "    # Crear etiquetas para visualización\n",
    "    labels = [\n",
    "        f\"{COCO_CLASSES[class_id]} {confidence:.2f}\"\n",
    "        for class_id, confidence\n",
    "        in zip(detections.class_id, detections.confidence)\n",
    "    ]\n",
    "    \n",
    "    # Anotar el frame con detecciones\n",
    "    annotated_frame = frame.copy()\n",
    "    annotated_frame = sv.BoxAnnotator().annotate(annotated_frame, detections)\n",
    "    annotated_frame = sv.LabelAnnotator().annotate(annotated_frame, detections, labels)\n",
    "    \n",
    "    # Mostrar el número de objetos únicos detectados\n",
    "    cv2.putText(\n",
    "        annotated_frame, \n",
    "        f\"Objetos únicos: {len(objects_registry)}\", \n",
    "        (10, 30), \n",
    "        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "        1, \n",
    "        (0, 255, 0), \n",
    "        2\n",
    "    )\n",
    "    \n",
    "    # Mostrar el frame anotado\n",
    "    cv2.imshow(\"Webcam\", annotated_frame)\n",
    "    \n",
    "    # Salir si se presiona 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar recursos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrain weights\n",
      "Objeto de interés detectado: book - Imagen guardada: detecciones/book_20250402_181903.jpg\n",
      "Objeto de interés detectado: cup - Imagen guardada: detecciones/cup_20250402_181936.jpg\n",
      "Objeto de interés detectado: cup - Imagen guardada: detecciones/cup_20250402_181942.jpg\n",
      "Objeto de interés detectado: cup - Imagen guardada: detecciones/cup_20250402_182048.jpg\n",
      "\n",
      "===== RESUMEN DE LA SESIÓN =====\n",
      "Duración total: 181.46 segundos\n",
      "Total de objetos de interés detectados: 11\n",
      "Total de imágenes registradas: 4\n",
      "Objetos de interés detectados:\n",
      "  - cup: 10 veces\n",
      "  - book: 1 veces\n",
      "\n",
      "Informe guardado en: estadisticas/resumen_20250402_182201.png\n",
      "Imágenes guardadas en: detecciones/\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import time\n",
    "import supervision as sv\n",
    "from datetime import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from rfdetr import RFDETRBase\n",
    "from rfdetr.util.coco_classes import COCO_CLASSES\n",
    "import matplotlib\n",
    "# Configurar matplotlib para no usar GUI\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración de directorios\n",
    "os.makedirs(\"detecciones\", exist_ok=True)\n",
    "os.makedirs(\"estadisticas\", exist_ok=True)\n",
    "\n",
    "# Definir objetos de interés con configuraciones personalizadas\n",
    "OBJETOS_DE_INTERES = {\n",
    "    \"cup\": {\"prioridad\": \"media\", \"color\": (0, 0, 255)},\n",
    "    \"knife\": {\"prioridad\": \"alta\", \"color\": (255, 165, 0)},\n",
    "    \"book\": {\"prioridad\": \"baja\", \"color\": (255, 0, 255)},\n",
    "}\n",
    "\n",
    "# Inicializar modelo\n",
    "model = RFDETRBase(resolution=448)\n",
    "\n",
    "# Inicializar webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "# Variables para estadísticas y seguimiento (solo para objetos de interés)\n",
    "estadisticas = {\n",
    "    \"total_detecciones\": defaultdict(int),\n",
    "    \"registros_generados\": defaultdict(int),\n",
    "    \"confianza_promedio\": defaultdict(list),\n",
    "    \"historial_tiempo\": [],\n",
    "    \"historial_detecciones\": []\n",
    "}\n",
    "\n",
    "# Tiempo mínimo entre registros del mismo tipo (en segundos)\n",
    "tiempo_entre_registros = 5\n",
    "ultimo_registro = defaultdict(float)\n",
    "\n",
    "# Funciones de utilidad\n",
    "def registrar_deteccion(frame, objeto, confianza, bbox):\n",
    "    \"\"\"Guarda una captura del frame con la detección destacada\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"detecciones/{objeto}_{timestamp}.jpg\"\n",
    "\n",
    "    # Destacar el objeto detectado\n",
    "    highlighted = frame.copy()\n",
    "    x1, y1, x2, y2 = [int(c) for c in bbox]\n",
    "    color = OBJETOS_DE_INTERES[objeto][\"color\"]\n",
    "    cv2.rectangle(highlighted, (x1, y1), (x2, y2), color, 4)\n",
    "    cv2.putText(highlighted, f\"{objeto} ({confianza:.2f})\", (x1, y1-10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Añadir información de la detección\n",
    "    info_text = f\"DETECCIÓN: {objeto} | Prioridad: {OBJETOS_DE_INTERES[objeto]['prioridad'].upper()} | Confianza: {confianza:.2f} | {timestamp}\"\n",
    "    cv2.putText(highlighted, info_text, (10, frame.shape[0]-20),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.imwrite(filename, highlighted)\n",
    "    return filename\n",
    "\n",
    "# Bucle principal de captura y procesamiento\n",
    "try:\n",
    "    prev_time = time.time()\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        prev_time = current_time\n",
    "\n",
    "        # Timestamp para este frame\n",
    "        timestamp = datetime.now()\n",
    "\n",
    "        # Ejecutar la detección\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        detections = model.predict(rgb_frame, threshold=0.45)\n",
    "\n",
    "        # Filtrar solo los objetos de interés\n",
    "        filtered_indexes = []\n",
    "        filtered_boxes = []\n",
    "        filtered_class_ids = []\n",
    "        filtered_confidences = []\n",
    "        filtered_labels = []\n",
    "        filtered_colors = []\n",
    "\n",
    "        objetos_en_escena = defaultdict(int)\n",
    "        total_objetos_interes = 0\n",
    "\n",
    "        # Filtrar detecciones para incluir solo objetos de interés\n",
    "        for i, (class_id, confidence, box) in enumerate(zip(\n",
    "                detections.class_id,\n",
    "                detections.confidence,\n",
    "                detections.xyxy)):\n",
    "\n",
    "            class_name = COCO_CLASSES[class_id]\n",
    "\n",
    "            # Solo procesar si es un objeto de interés\n",
    "            if class_name in OBJETOS_DE_INTERES:\n",
    "                filtered_indexes.append(i)\n",
    "                filtered_boxes.append(box)\n",
    "                filtered_class_ids.append(class_id)\n",
    "                filtered_confidences.append(confidence)\n",
    "\n",
    "                # Incrementar contador para este objeto\n",
    "                objetos_en_escena[class_name] += 1\n",
    "                total_objetos_interes += 1\n",
    "\n",
    "                # Añadir a estadísticas\n",
    "                estadisticas[\"total_detecciones\"][class_name] += 1\n",
    "                estadisticas[\"confianza_promedio\"][class_name].append(float(confidence))\n",
    "\n",
    "                # Preparar etiqueta y color para visualización\n",
    "                color = OBJETOS_DE_INTERES[class_name][\"color\"]\n",
    "                prioridad = OBJETOS_DE_INTERES[class_name][\"prioridad\"]\n",
    "                label = f\"{class_name} [{prioridad.upper()}]\"\n",
    "                filtered_labels.append(label)\n",
    "                filtered_colors.append(color)\n",
    "\n",
    "                # Verificar si debemos registrar esta detección\n",
    "                tiempo_actual = time.time()\n",
    "                if tiempo_actual - ultimo_registro[class_name] > tiempo_entre_registros:\n",
    "                    # Registrar detección con captura de pantalla\n",
    "                    imagen_deteccion = registrar_deteccion(frame, class_name, confidence, box)\n",
    "\n",
    "                    # Actualizar tiempo del último registro\n",
    "                    ultimo_registro[class_name] = tiempo_actual\n",
    "                    estadisticas[\"registros_generados\"][class_name] += 1\n",
    "\n",
    "                    print(f\"Objeto de interés detectado: {class_name} - Imagen guardada: {imagen_deteccion}\")\n",
    "\n",
    "        # Actualizar historial solo si hay objetos de interés\n",
    "        if len(filtered_indexes) > 0:\n",
    "            estadisticas[\"historial_tiempo\"].append(timestamp)\n",
    "            estadisticas[\"historial_detecciones\"].append(total_objetos_interes)\n",
    "\n",
    "        # Crear un frame limpio para visualización (sin anotaciones)\n",
    "        clean_frame = frame.copy()\n",
    "\n",
    "        # Dibujar solo los objetos de interés filtrados manualmente\n",
    "        for i, (box, label, color) in enumerate(zip(filtered_boxes, filtered_labels, filtered_colors)):\n",
    "            x1, y1, x2, y2 = [int(c) for c in box]\n",
    "            # Dibujar rectángulo\n",
    "            cv2.rectangle(clean_frame, (x1, y1), (x2, y2), color, 2)\n",
    "            # Añadir etiqueta\n",
    "            cv2.putText(clean_frame, label, (x1, y1-10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "\n",
    "        # Mostrar FPS\n",
    "        cv2.putText(clean_frame, f\"FPS: {fps:.1f}\", (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "        # Mostrar solo el frame con las detecciones\n",
    "        cv2.imshow(\"Monitoreo de Objetos\", clean_frame)\n",
    "\n",
    "        # Salir con 'q'\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Detenido por el usuario\")\n",
    "finally:\n",
    "    # Liberar recursos\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Si no hay detecciones, mostrar mensaje y salir\n",
    "    if not estadisticas[\"total_detecciones\"]:\n",
    "        print(\"No se detectaron objetos de interés durante la sesión.\")\n",
    "        exit()\n",
    "\n",
    "    # Guardar estadísticas finales\n",
    "    timestamp_final = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Generar gráfico de resumen (solo objetos de interés)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Gráfico 1: Total de detecciones\n",
    "    plt.subplot(2, 2, 1)\n",
    "    objetos = list(estadisticas[\"total_detecciones\"].keys())\n",
    "    valores = list(estadisticas[\"total_detecciones\"].values())\n",
    "    plt.bar(objetos, valores)\n",
    "    plt.title('Total de Detecciones de Objetos de Interés')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Gráfico 2: Registros generados\n",
    "    plt.subplot(2, 2, 2)\n",
    "    objetos = list(estadisticas[\"registros_generados\"].keys())\n",
    "    valores = list(estadisticas[\"registros_generados\"].values())\n",
    "    plt.bar(objetos, valores, color='orange')\n",
    "    plt.title('Imágenes Registradas por Objeto')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Gráfico 3: Confianza promedio\n",
    "    plt.subplot(2, 2, 3)\n",
    "    objetos = []\n",
    "    valores = []\n",
    "    for obj, confianzas in estadisticas[\"confianza_promedio\"].items():\n",
    "        if confianzas:\n",
    "            objetos.append(obj)\n",
    "            valores.append(sum(confianzas) / len(confianzas))\n",
    "    plt.bar(objetos, valores, color='green')\n",
    "    plt.title('Confianza Promedio por Objeto')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    # Gráfico 4: Timeline de detecciones\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(estadisticas[\"historial_tiempo\"], estadisticas[\"historial_detecciones\"])\n",
    "    plt.title('Objetos de Interés Detectados en el Tiempo')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # Guardar el gráfico sin mostrarlo\n",
    "    plt.savefig(f\"estadisticas/resumen_{timestamp_final}.png\")\n",
    "    plt.close()  # Cerrar la figura después de guardarla\n",
    "\n",
    "    print(\"\\n===== RESUMEN DE LA SESIÓN =====\")\n",
    "    total_tiempo = 0\n",
    "    if estadisticas[\"historial_tiempo\"]:\n",
    "        total_tiempo = (datetime.now() - estadisticas[\"historial_tiempo\"][0]).total_seconds()\n",
    "\n",
    "    print(f\"Duración total: {total_tiempo:.2f} segundos\")\n",
    "    print(f\"Total de objetos de interés detectados: {sum(estadisticas['total_detecciones'].values())}\")\n",
    "    print(f\"Total de imágenes registradas: {sum(estadisticas['registros_generados'].values())}\")\n",
    "    print(f\"Objetos de interés detectados:\")\n",
    "    for obj, count in sorted(estadisticas[\"total_detecciones\"].items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"  - {obj}: {count} veces\")\n",
    "\n",
    "    print(f\"\\nInforme guardado en: estadisticas/resumen_{timestamp_final}.png\")\n",
    "    print(f\"Imágenes guardadas en: detecciones/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
